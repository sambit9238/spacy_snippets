{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keyword_extraction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMv19M41hftH1Sm8aN4GAqP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkLqlS-hDRN9",
        "outputId": "d2242f33-767d-4f60-9ffa-2bb2628e93dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip3 install rake-nltk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rake-nltk\n",
            "  Downloading https://files.pythonhosted.org/packages/8e/c4/b4ff57e541ac5624ad4b20b89c2bafd4e98f29fd83139f3a81858bdb3815/rake_nltk-1.0.4.tar.gz\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rake-nltk) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->rake-nltk) (1.15.0)\n",
            "Building wheels for collected packages: rake-nltk\n",
            "  Building wheel for rake-nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rake-nltk: filename=rake_nltk-1.0.4-py2.py3-none-any.whl size=7819 sha256=ea2fb16e3e627f377a03ed85ec7b56699b1f7d17478700327f5ff42b7f010e68\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/92/fc/271b3709e71a96ffe934b27818946b795ac6b9b8ff8682483f\n",
            "Successfully built rake-nltk\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CM1Agu3hSK42",
        "outputId": "0a4399db-eba8-4e5d-f830-cfb05b13f467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "!pip3 install mrakun"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mrakun\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/be/6712ffbd58e2245dcbaac9f26d40f0ad5eaa4496760dff3f0a97beb844c2/mrakun-0.43.tar.gz (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from mrakun) (3.2.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from mrakun) (2.5)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from mrakun) (0.5.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mrakun) (1.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mrakun) (1.18.5)\n",
            "Collecting py3plex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/25/8967ab8397b870b3819201403f41bd0f0112621794c0ad36a3798f415df8/py3plex-0.76.tar.gz (77.4MB)\n",
            "\u001b[K     |████████████████████████████████| 77.4MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->mrakun) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->mrakun) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->mrakun) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mrakun) (2018.9)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 53.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from py3plex->mrakun) (1.4.1)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->py3plex->mrakun) (2.4.7)\n",
            "Building wheels for collected packages: mrakun, py3plex\n",
            "  Building wheel for mrakun (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mrakun: filename=mrakun-0.43-cp36-none-any.whl size=18971 sha256=72f2ce60ddd70f3b0e9851cfdb6700d630acfdcc2bc1a539c5ee179357e78313\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/90/23/64d11805ec58b8471d4eac7e3415cc40006712d3665c7b3eac\n",
            "  Building wheel for py3plex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py3plex: filename=py3plex-0.76-cp36-none-any.whl size=10829352 sha256=f5ab33f3e533e605e8c332fc3be1533583011bc1d8a4b518ec2b52d2d0a543cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/d9/18/874252b01d594c9db9f78e1eee6476200c0d108b19a5101b04\n",
            "Successfully built mrakun py3plex\n",
            "Installing collected packages: isodate, rdflib, py3plex, mrakun\n",
            "Successfully installed isodate-0.6.0 mrakun-0.43 py3plex-0.76 rdflib-5.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXPhNG2KGPpN",
        "outputId": "96e70eaf-a67e-4faa-9d36-293e4a594f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install git+https://github.com/boudinfl/pke.git\n",
        "!python -m nltk.downloader stopwords\n",
        "!python -m spacy download en"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-d02pl6vk\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-d02pl6vk\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (3.2.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.4.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (2.2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (1.15.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.0)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pke==1.8.1) (0.16.0)\n",
            "Collecting langcodes\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/f7/51b1d31a1ec3023c8eb4b2e11e1571d714c990fa64baf352d5a30f6f9d83/langcodes-2.1.0.tar.gz (5.0MB)\n",
            "\u001b[K     |████████████████████████████████| 5.0MB 49.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pke==1.8.1) (4.4.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (2.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pke==1.8.1) (7.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->pke==1.8.1) (0.22.2.post1)\n",
            "Collecting marisa-trie\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke==1.8.1) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pke==1.8.1) (3.1.0)\n",
            "Building wheels for collected packages: pke, langcodes, marisa-trie\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-1.8.1-cp36-none-any.whl size=8761404 sha256=0877f5fe1e06cdd3aeb1ea6d2cc293e43348bb230a8ded87ed499e489b940379\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hdpj05_5/wheels/8d/24/54/6582e854e9e32dd6c632af6762b3a5d2f6b181c2992e165462\n",
            "  Building wheel for langcodes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langcodes: filename=langcodes-2.1.0-cp36-none-any.whl size=5068034 sha256=b903dad0992509c5ed29e65278f5bb230201dbbe3a87e0a82b0dbd23a9ce26f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/aa/f5/285652c17bb68a5f6d30bdfeebb517d210cabe18268fcb80b5\n",
            "  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=861393 sha256=bc4f291803bb862c039e9af6d58d50a7b2a95392f2f94c933e94c7d9d388214d\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n",
            "Successfully built pke langcodes marisa-trie\n",
            "Installing collected packages: unidecode, marisa-trie, langcodes, pke\n",
            "Successfully installed langcodes-2.1.0 marisa-trie-0.7.5 pke-1.8.1 unidecode-1.1.1\n",
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEGuII6QDIi1"
      },
      "source": [
        "from rake_nltk import Rake\n",
        "rake = Rake()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnNNy1lzGl8N"
      },
      "source": [
        "from pke.unsupervised import YAKE\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEpTMaoYShJO"
      },
      "source": [
        "from mrakun import RakunDetector"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LjlASB7HE-v"
      },
      "source": [
        "def rake_rank(text, num=4):\n",
        "  rake.extract_keywords_from_text(text)\n",
        "  #print(rake.get_ranked_phrases_with_scores())\n",
        "  return sorted(rake.get_ranked_phrases_with_scores(), key = lambda x: x[0], reverse=True)[:num]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aamloxmG_Be",
        "outputId": "77f14e5a-6610-4550-b9f2-f3940623ae2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "dir(rake)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_build_frequency_dist',\n",
              " '_build_ranklist',\n",
              " '_build_word_co_occurance_graph',\n",
              " '_generate_phrases',\n",
              " '_get_phrase_list_from_words',\n",
              " 'degree',\n",
              " 'extract_keywords_from_sentences',\n",
              " 'extract_keywords_from_text',\n",
              " 'frequency_dist',\n",
              " 'get_ranked_phrases',\n",
              " 'get_ranked_phrases_with_scores',\n",
              " 'get_word_degrees',\n",
              " 'get_word_frequency_distribution',\n",
              " 'max_length',\n",
              " 'metric',\n",
              " 'min_length',\n",
              " 'punctuations',\n",
              " 'rank_list',\n",
              " 'ranked_phrases',\n",
              " 'stopwords',\n",
              " 'to_ignore']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhvY4P-VIyCj"
      },
      "source": [
        "stoplist = stopwords.words('english')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9xJ9SFOSW0i",
        "outputId": "3f91104a-23cf-4f9b-d825-0663b188ae3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "def rakun_rank(text, num=4):\n",
        "  hyperparameters = {\"distance_threshold\":2,\n",
        "                    \"distance_method\": \"editdistance\",\n",
        "                    \"num_keywords\" : 10,\n",
        "                    \"pair_diff_length\":2,\n",
        "                    \"stopwords\" : stoplist,\n",
        "                    \"bigram_count_threshold\":2,\n",
        "                    \"num_tokens\":[1,2],\n",
        "        \"max_similar\" : 3, ## n most similar can show up n times\n",
        "        \"max_occurrence\" : 3} ## maximum frequency overall\n",
        "\n",
        "  keyword_detector = RakunDetector(hyperparameters)\n",
        "  keywords = keyword_detector.find_keywords(text, input_type = \"text\")\n",
        "  return sorted(keywords, key = lambda x: x[1], reverse=True)[:num]\n",
        "  #keyword_detector.visualize_network()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
            "Wall time: 9.54 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIlPf7PjDZ-O",
        "outputId": "5c9e1c57-ee2c-4734-d6ab-40591bc42c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "extractor = YAKE()\n",
        "def yake_rank(text):\n",
        "  # 1. Create YAKE keyword extractor\n",
        "  # 2. Load document\n",
        "  extractor.load_document(input=text,\n",
        "                          language='en',\n",
        "                          normalization=None)\n",
        "\n",
        "  # 3. Generate candidate 1-gram and 2-gram keywords\n",
        "  extractor.candidate_selection(n=3, stoplist=stoplist)\n",
        "\n",
        "  # 4. Calculate scores for the candidate keywords\n",
        "  extractor.candidate_weighting(window=2,\n",
        "                                stoplist=stoplist,\n",
        "                                use_stems=False)\n",
        "\n",
        "  # 5. Select 10 highest ranked keywords\n",
        "  # Remove redundant keywords with similarity above 80%\n",
        "  key_phrases = extractor.get_n_best(n=4, threshold=0.8)\n",
        "  return key_phrases"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 286 µs, sys: 20 µs, total: 306 µs\n",
            "Wall time: 312 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIoLzh_jGsgx",
        "outputId": "5ad87ace-c5f1-4c3a-828f-e0d23c15f393",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "text = '\"too much of an echo when on speaker~phone.\", \"and w/o speaker phone your cheek pushing against the buttons. thanx, sami c.\"'\n",
        "rake_rank(text), yake_rank(text)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(9.0, 'sami c .\"'),\n",
              "  (4.0, 'cheek pushing'),\n",
              "  (3.0, 'speaker phone'),\n",
              "  (1.5, 'speaker')],\n",
              " [('speaker', 0.2589678339469337),\n",
              "  ('phone', 0.2589678339469337),\n",
              "  ('much', 0.28498490135981175),\n",
              "  ('echo', 0.28498490135981175)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKBDxP3MHr2L",
        "outputId": "556caebd-6772-4aab-f0b5-7f8fcc92c31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "text = [\"see photos attached. we bought a size up\", \"none of her nike shoes have ever developed holes, even after 6 months of wearing them. is there any warranty on these?\", \"what can we do about this?\"]\n",
        "\n",
        "for each in text:\n",
        "  print(each, '\\n')\n",
        "  %time print(\"rake : \", rake_rank(each), '\\n')\n",
        "  %time print(\"yake : \", yake_rank(each), '\\n')\n",
        "  %time print(\"rakun : \", rakun_rank(each), '\\n')\n",
        "  print('...........................')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "see photos attached. we bought a size up \n",
            "\n",
            "rake :  [(9.0, 'see photos attached'), (1.0, 'size'), (1.0, 'bought')] \n",
            "\n",
            "CPU times: user 965 µs, sys: 0 ns, total: 965 µs\n",
            "Wall time: 979 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27-Sep-20 06:50:23 - Initiated a keyword detector instance.\n",
            "27-Sep-20 06:50:23 - Number of nodes reduced from 3 to 3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "yake :  [('see photos attached', 0.006249869637814998), ('see photos', 0.038712704770480444), ('photos attached', 0.038712704770480444), ('see', 0.1531727145735673)] \n",
            "\n",
            "CPU times: user 582 ms, sys: 23.9 ms, total: 606 ms\n",
            "Wall time: 609 ms\n",
            "rakun :  [('attached', 0.5), ('photos', 0.0), ('bought', 0.0)] \n",
            "\n",
            "CPU times: user 2.97 ms, sys: 1 ms, total: 3.97 ms\n",
            "Wall time: 4.11 ms\n",
            "...........................\n",
            "none of her nike shoes have ever developed holes, even after 6 months of wearing them. is there any warranty on these? \n",
            "\n",
            "rake :  [(9.0, 'ever developed holes'), (4.0, 'nike shoes'), (4.0, '6 months'), (1.0, 'wearing')] \n",
            "\n",
            "CPU times: user 1.09 ms, sys: 5 µs, total: 1.09 ms\n",
            "Wall time: 1.1 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27-Sep-20 06:50:23 - Initiated a keyword detector instance.\n",
            "27-Sep-20 06:50:23 - Number of nodes reduced from 6 to 6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "yake :  [('see photos attached', 0.0025872531000991623), ('ever developed holes', 0.003845561146517792), ('see photos', 0.02111158115940884), ('photos attached', 0.02111158115940884)] \n",
            "\n",
            "CPU times: user 478 ms, sys: 25 ms, total: 503 ms\n",
            "Wall time: 504 ms\n",
            "rakun :  [('months', 0.30000000000000004), ('holes', 0.30000000000000004), ('wearing', 0.2), ('developed', 0.2)] \n",
            "\n",
            "CPU times: user 4.39 ms, sys: 92 µs, total: 4.48 ms\n",
            "Wall time: 4.53 ms\n",
            "...........................\n",
            "what can we do about this? \n",
            "\n",
            "rake :  [] \n",
            "\n",
            "CPU times: user 785 µs, sys: 0 ns, total: 785 µs\n",
            "Wall time: 892 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "27-Sep-20 06:50:24 - Initiated a keyword detector instance.\n",
            "27-Sep-20 06:50:24 - Number of nodes reduced from 0 to 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "yake :  [('see photos attached', 0.0010326977494654298), ('ever developed holes', 0.0015511324559800282), ('see photos', 0.011576079587222952), ('photos attached', 0.011576079587222952)] \n",
            "\n",
            "CPU times: user 558 ms, sys: 20.7 ms, total: 579 ms\n",
            "Wall time: 581 ms\n",
            "rakun :  [] \n",
            "\n",
            "CPU times: user 2.56 ms, sys: 18 µs, total: 2.58 ms\n",
            "Wall time: 2.16 ms\n",
            "...........................\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct9dYd95Jt3l"
      },
      "source": [
        "Noun phrases and named entities that are fully numeric.\n",
        "• Named entities that belong to the following categories\n",
        "are filtered out : DATE, TIME, PERCENT, MONEY,\n",
        "QUANTITY, ORDINAL, CARDINAL. Refer, Spacy’s\n",
        "named entity documentation2\n",
        "for details of the tags.\n",
        "• Standard stopwords are removed.\n",
        "• Punctuations are removed except ’-’.\n",
        "\n",
        "• Common adjectives and reporting verbs are removed\n",
        "if they occur as the first or last token of a noun\n",
        "phrase/named entity.\n",
        "• Determiners are removed from the first token of a noun\n",
        "phrase/named entity.\n",
        "• First or last tokens of noun phrases/named entities belonging to following parts of speech: INTJ Interjection,\n",
        "AUX Auxiliary, CCONJ Coordinating Conjunction,\n",
        "ADP Adposition, DET Interjection, NUM Numeral,\n",
        "PART Particle, PRON Pronoun, SCONJ Subordinating\n",
        "Conjunction, PUNCT Punctutation, SYM Symbol, X\n",
        "Other, are removed. For a detailed reference of each of\n",
        "these POS tags please refer Spacy’s documentation3\n",
        ".\n",
        "• Starting and ending tokens of a noun phrase/named entity\n",
        "is removed if they belong to a standard list of english\n",
        "stopwords.\n",
        "• Starting and ending tokens of a noun phrase/named entity\n",
        "is removed if they belong to a standard list of english\n",
        "functional words.\n",
        "\n",
        "• Get rid of leading/trailing junk characters.\n",
        "• Handle dangling/backwards parentheses. We don’t allow\n",
        "’(’ or ’)’ to appear without the other.\n",
        "• Handle oddly separated hyphenated words.\n",
        "• Handle oddly separated apostrophe’d words.\n",
        "• Normalize whitespace."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RibVbYbzgTtf",
        "outputId": "088128f6-884c-4a62-86a2-6f0c42f4a83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "!pip3 install pytextrank"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytextrank\n",
            "  Downloading https://files.pythonhosted.org/packages/38/97/3cd3ec7396b6cb5984d860b18a8741f59d4652c8bbfc7b7431e9831e5d53/pytextrank-2.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from pytextrank) (3.7.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from pytextrank) (0.10.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pytextrank) (2.2.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from pytextrank) (2.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (0.8.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (50.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pytextrank) (4.41.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->pytextrank) (4.4.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pytextrank) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pytextrank) (3.1.0)\n",
            "Installing collected packages: pytextrank\n",
            "Successfully installed pytextrank-2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKmFbm_lgTwI"
      },
      "source": [
        "import spacy, re\n",
        "from spacy.matcher import Matcher\n",
        "import pytextrank\n",
        "\n",
        "boundary = re.compile('^[0-9]$')\n",
        "pattern_1 = [\n",
        "            [{\"LOWER\": \"hello\"}, {\"IS_ASCII\": True}],\n",
        "            [{\"LOWER\": \"hey\"}, {\"IS_ASCII\": True}],\n",
        "            [{\"LOWER\": \"hi\"}, {\"IS_ASCII\": True}],\n",
        "            [{'LOWER': 'good'}, {'ENT_TYPE': 'TIME'}, {\"IS_ASCII\": True}]\n",
        "        ]\n",
        "pattern_2 = [{'ORTH': 'thank'}, {'ORTH': 'you'}] #thank you statements\n",
        "def custom_seg(doc):\n",
        "    prev = doc[0].text\n",
        "    length = len(doc)\n",
        "    for index, token in enumerate(doc):\n",
        "        if (\n",
        "            (token.text == '.' and boundary.match(prev) and index!=(length - 1)) or\n",
        "               token.text == '>' or (token.text == ' ' and prev == '>')\n",
        "           ):\n",
        "            doc[index+1].sent_start = False\n",
        "        prev = token.text\n",
        "    return doc\n",
        "\n",
        "\n",
        "tr = pytextrank.TextRank()\n",
        "\n",
        "class Spacy_Utilities:\n",
        "    def __init__(self, disable_ops=[]):\n",
        "        self.nlp = spacy.load('en_core_web_sm')\n",
        "        self.nlp.add_pipe(custom_seg, before='parser')\n",
        "        self.nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
        "        self.matcher = Matcher(self.nlp.vocab)\n",
        "        self.matcher.add(\"greet\", None, *pattern_1)\n",
        "        self.matcher.add(\"not_qc\", None, pattern_2)\n",
        "        #self.nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
        "    def greet_pattern_matcher(self):\n",
        "        return self.matcher\n",
        "    def process_doc(self, text):\n",
        "        doc = self.nlp(text)\n",
        "        return doc\n",
        "    def sent_tokenize(self, text):\n",
        "        return text.sents\n",
        "    def ent_words_extract(self, text):\n",
        "        return [X.text.split() for X in text.ents]\n",
        "    def ent_labels_extract(self, text):\n",
        "        return [X.label_ for X in text.ents]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOuyygYzhK8s"
      },
      "source": [
        "spacy_en = Spacy_Utilities()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ey65_cNgaBV"
      },
      "source": [
        " questions = [\"The ranked keywords are evaluated using exact match\",\n",
        "\"evaluation metric as used in SemEval 2010 Task 5. We match\",\n",
        "\"the keywords in the annotated documents in the benchmark. datasets with those generated by our method, and calculate. micro-averaged precision, recall and F-score (β = 1), respectively. In the evaluation, we check the performance over\",\n",
        "\"the top 5, 10 and 15 candidates returned by our system.\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HFU1gR-g_-p",
        "outputId": "e6505e3d-ab7d-4b30-c9bd-c45c478054bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tmp_questions_arr = []\n",
        "for question_doc in spacy_en.nlp.pipe([questions[2]]):\n",
        "        tmp_arr = [sent.text for sent in question_doc.sents]\n",
        "        tmp_questions_arr.append( \" \".join(tmp_arr[-3:]) )\n",
        "print(tmp_questions_arr)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['datasets with those generated by our method, and calculate. micro-averaged precision, recall and F-score (β = 1), respectively. In the evaluation, we check the performance over']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfS2B_59isob"
      },
      "source": [
        "import numpy as np\n",
        "NEUTRAL = 'neutral'\n",
        "S_POS   = 'slight_positive'\n",
        "POS     = 'positive'\n",
        "S_NEG   = 'slight_negative'\n",
        "NEG     = 'negative'\n",
        "\n",
        "def decide_label(rslt_arr):\n",
        "    max_id = np.argmax(rslt_arr)\n",
        "    if max_id == 1:\n",
        "        return NEUTRAL\n",
        "    elif max_id == 0:\n",
        "        if rslt_arr[0] > 0.6:\n",
        "            return NEG\n",
        "        elif rslt_arr[0] <= 0.6 :\n",
        "            return S_NEG\n",
        "    elif max_id == 2:\n",
        "        if rslt_arr[2] > 0.6:\n",
        "            return POS\n",
        "        elif rslt_arr[2] <= 0.6:\n",
        "            return S_POS"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4VIqUVYhJgS"
      },
      "source": [
        "import json, requests\n",
        "from typing import List\n",
        "def do_sentiment_evaluation(ip_list: List[str]):\n",
        "    url = f\"http://34.72.3.36/v1/models/sentiment:predict\"\n",
        "    headers = {\n",
        "    'content-type': 'application/json'\n",
        "    }\n",
        "    payload = json.dumps({\n",
        "        \"inputs\": ip_list\n",
        "        })\n",
        "    response = requests.request(\"POST\", url, headers=headers, data = payload)\n",
        "    rslt = json.loads(response.text.encode('utf8'))\n",
        "    print(f\"SENTIMENT RESULT {rslt}\")\n",
        "    sentiment_op = [decide_label(each) for each in rslt['outputs']]\n",
        "    return sentiment_op"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px2FdNvyi-nE",
        "outputId": "8197383e-a145-480f-a633-96a72fa7c5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "do_sentiment_evaluation(tmp_questions_arr)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SENTIMENT RESULT {'outputs': [[0.361043811, 0.436594546, 0.202361614]]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neutral']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSM8lp6bjG21"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}